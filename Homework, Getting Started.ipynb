{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of a quadruped Robot\n",
    "\n",
    "\n",
    "Using the simulator the goal of this challenge is to come up with an Agent for controlling a Quadrupedal Robot on a flat environement. The best solution will be the solution that goes as far as possible given a number of Timesteps\n",
    "\n",
    "## Using the Environment\n",
    "\n",
    "You are provided with an environment that uses the [OpenAI Gym Interface](https://gym.openai.com/). \n",
    "\n",
    "Once initialized, you can interact with the environment using the step function that takes a set of actions ( a numpy array of size 12 between -1.0 and 1.0 that corresponds to target angles for each joints. ) \n",
    "The order of the joint angles is as follow [knee, hip, shoulder] for each of the legs in order [Front Left, Rear Right, Front Right, Rear Left]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aida_env.aida_gym_env as e\n",
    "import pybullet as p\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env = e.AidaBulletEnv(render=True, on_rack=True)  #  use on_rack to remove gravity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each joint moving one by one. \n",
    "class Agent():\n",
    "    def get_actions(self, joint, v):\n",
    "        actions = np.zeros(12)\n",
    "        actions[joint] = v\n",
    "        return actions\n",
    "\n",
    "agent = Agent()\n",
    "\n",
    "for i in range(200):\n",
    "     env.step(np.zeros(12))  # init\n",
    "for i in range(1200):\n",
    "    joint = int(i / 100) # go through each joint one by one\n",
    "    angle = (int(i / 50) % 2 - 1.0) # alternate between max and min angle for each joint. \n",
    "    env.render()\n",
    "    env.step(agent.get_actions(joint, angle)) # take a random actio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing an Agent\n",
    "\n",
    "You can write an Agent to control the actions sent to the environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Close the windows and the env.\n",
    "p.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = e.AidaBulletEnv(render=True, on_rack=False)  #  use on_rack to remove gravity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A small baseline example.\n",
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.t = 0\n",
    "        \n",
    "    def get_actions(self):\n",
    "        self.t += 1\n",
    "        if self.t < 200:\n",
    "            return self.start()\n",
    "        \n",
    "        actions = self.circles(self.t)\n",
    "        actions_unsync = self.circles(self.t ,offset = np.pi )\n",
    "        actions = actions_unsync + actions_unsync + actions + actions\n",
    "        return actions\n",
    "    \n",
    "    def start(self):\n",
    "        return -0.5 * np.ones(12) # a good value to have the robot start on its legs\n",
    "\n",
    "    def circles(self, t, offset=0, speed=0.06):\n",
    "        return [-0.5 + np.sin(t * speed + offset) * 0.25, -0.5 + np.cos(t * speed + offset) * 0.25, -0.5]\n",
    "\n",
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2000):\n",
    "    env.step(agent.get_actions())\n",
    "    #print(env.aida.GetBasePosition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents\n",
    "\n",
    "An agent must contain a function named get_actions() (without any args, see example above) that will return the next set of actions to be performed on the environment. Make sure that this is respected so that the testing function work ( see below).\n",
    "The test function will test how far the robot goes and return the distance from the start. This will be used to evaluate your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aida_env.utils import test_agent_on_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_agent_on_env(agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
